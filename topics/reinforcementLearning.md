- [Reinforcement Learning](#reinforcement-learning)
  - [Pre-training](#pre-training)
  - [Transfer Learning](#transfer-learning)

# Reinforcement Learning

*A technique that teaches an A.I. model to find the best result by trial and error, receiving rewards or punishments from an algorithm based on its results. This system can be enhanced by humans giving feedback on its performance.*

## Pre-training

*Pretraining is the process of training an LLM on a large dataset, usually unsupervised or self-supervised, before fine-tuning it for a specific task. During pretraining, the model learns general language patterns, relationships between words, and other foundational knowledge. This process results in a pretrained model that can be fine-tuned using a smaller, task-specific dataset, significantly reducing the amount of labeled data and training time required to achieve high performance on various NLP tasks.*

## Transfer Learning

*Transfer learning is the technique of leveraging the knowledge gained during pretraining and applying it to a new, related task. In the context of LLMs, transfer learning involves fine-tuning a pretrained model on a smaller, task-specific dataset to achieve high performance on that task. The benefit of transfer learning is that it allows the model to benefit from the vast amount of general language knowledge learned during pretraining, reducing the need for large labeled datasets and extensive training for each new task.*